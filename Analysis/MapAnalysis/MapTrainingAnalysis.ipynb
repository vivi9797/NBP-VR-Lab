{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Training Analysis\n",
    "*written by Viviane Kakerbeck*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io as spio\n",
    "from scipy.spatial import distance\n",
    "import ezodf\n",
    "from matplotlib.patches import Arrow, Circle\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import ptitprince as pt\n",
    "from __future__ import print_function\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Paths\n",
    "These two fields need to be set for each user individually. Set mapPath to your path leading to your map training data and taskPath to lead to your alignment task results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapPath = \"/Users/ingen/Dropbox/VR alignment/bachelor_master_Arbeiten/Laura/scripts/viewed_data/\"\n",
    "#taskPath = \"/Users/ingen/Dropbox/VR alignment/bachelor_master_Arbeiten/Laura/scripts/over_all_subjects/trials_mat/\"\n",
    "#mapPath = \"/Users/ingen/Dropbox/Project Seahaven/Tracking/MapResults/\"\n",
    "#taskPath = \"/Users/ingen/Dropbox/Project Seahaven/Tracking/TaskPerformance/\"\n",
    "mapPath = \"C:/Users/vivia/Dropbox/Project Seahaven/Tracking/MapResults/\"\n",
    "taskPath = \"C:/Users/vivia/Dropbox/Project Seahaven/Tracking/TaskPerformance/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Dependencies:\n",
    "\n",
    "For this script you need the following files:\n",
    "* #.ods from Map training (location specified by mapPath)\n",
    "* AlignmentVR_SubjNo_#.mat from Task (location specified by taskPath)\n",
    "\n",
    "In the same folder as this script should be:\n",
    "\n",
    "* complete_list_houses.txt (for house angles)\n",
    "* HouseList.txt (for house coordinates)\n",
    "* Seahaven alingment project.csv -> download from google spreadsheet with list of all recordings & discard marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Training\n",
    "\n",
    "#### Function to Check Usability of a Subject (Discarded? Right Condition?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkUsability(SNum,Rep=False):\n",
    "    overview = pd.read_csv(\"./Seahaven alingment project.csv\")\n",
    "    if (overview.loc[overview['Subject#']==SNum].empty):\n",
    "        #print(str(SNum)+\" not in list.\")\n",
    "        if Rep == True:\n",
    "            return False,\" \"\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if (overview.loc[overview['Subject#']==SNum]['Discarded']=='yes').bool():\n",
    "            #print(str(SNum)+\" discarded.\")\n",
    "            if Rep == True:\n",
    "                return False,\" \"\n",
    "            else:\n",
    "                return False\n",
    "        if Rep==False:\n",
    "            if (overview.loc[overview['Subject#']==SNum]['Measurement#']>1).bool():\n",
    "                #print(str(SNum)+\" repeated measure.\")\n",
    "                return False\n",
    "    if Rep==True:\n",
    "        if (overview.loc[overview['Subject#']==SNum]['Repeated'].isnull()).bool():\n",
    "            return False,\" \"\n",
    "        else:\n",
    "            return True,(overview.loc[overview['Subject#']==SNum]['Repeated']).values[0]\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load All Map Training Data Into a DataFrame - For .osc Files\n",
    "Only run once! If you already have ClickStatsAll.csv saved just load this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "allFiles = os.listdir(mapPath)\n",
    "g = open(\"./complete_list_houses.txt\",\"r\")\n",
    "allHouses = []\n",
    "for i in g:\n",
    "    allHouses.append(str(int(i.split('_',1)[0])))\n",
    "AllDf = pd.DataFrame(allHouses,columns=['House'])\n",
    "\n",
    "for e in allFiles:\n",
    "    start = 0\n",
    "    lastI = 0\n",
    "    lastV = 0\n",
    "    if e.endswith(\".ods\") and checkUsability(int(e.split('.',1)[0])):\n",
    "        doc = ezodf.opendoc(mapPath+e)\n",
    "        sheet = doc.sheets[0]\n",
    "        for i, row in enumerate(sheet.rows()):\n",
    "            for cell in row:\n",
    "                if cell.value=='Mouse Click Stats:':#only get mouse click stats, not hovering\n",
    "                    start = i\n",
    "                    Subjectdf = pd.DataFrame(columns=['House',str(int(e.split('.',1)[0]))])\n",
    "\n",
    "                if start>0 and start<i-1 and cell.value!=None:\n",
    "\n",
    "                    if lastI==i:\n",
    "                        #print(str(int(lastV.split('_',1)[0])))#.split('\\t',1)[1].split('\\n',1)[0])\n",
    "                        Subjectdf = Subjectdf.append({'House': str(int(lastV.split('_',1)[0])),str(e.split('.',1)[0]):int(cell.value)}, ignore_index=True)\n",
    "                lastI = i\n",
    "                lastV = cell.value\n",
    "        AllDf = AllDf.merge(Subjectdf,on='House',sort=True,how='outer')\n",
    "AllDf = AllDf.fillna(int(0))          \n",
    "AllDf = AllDf.set_index('House')\n",
    "AllDf = AllDf[~AllDf.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Table in Excel Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDf.to_csv('Results/ClickStatsAll.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Look at Map Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDf = pd.read_csv('Results/ClickStatsAll.csv').set_index('House')\n",
    "len(AllDf.columns)# following analysis is of 64 subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excerpt from Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(AllDf.mean(axis=1),norm_hist=False,kde=False,color='royalblue')# if you don't want pdf, set norm_hist=False,kde=False\n",
    "plt.plot([np.mean(AllDf.mean(axis=1)), np.mean(AllDf.mean(axis=1))], [0, 41], linewidth=2)\n",
    "plt.legend(['mean: '+str(np.mean(AllDf.mean(axis=1)))[:4],'distribution'],fontsize=15)\n",
    "plt.title(\"Distribution of Mean Number of Clicks on one House over Subjects\",fontsize=20)\n",
    "plt.xlabel('Mean Number of Clicks on one House',fontsize=15)\n",
    "plt.ylabel('Subject Count',fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig('Results/MeanClickDistNoTitle.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(AllDf.sum(axis=1),color='royalblue')\n",
    "plt.plot([np.mean(AllDf.sum(axis=1)), np.mean(AllDf.sum(axis=1))], [0, 0.0037], linewidth=2)\n",
    "plt.legend(['mean: '+str(np.mean(AllDf.sum(axis=1)))[:4],'distribution'],fontsize=15)\n",
    "plt.title(\"Distribution of Overall Number of Clicks on one House over Subjects\",fontsize=20)\n",
    "plt.xlabel('Mean Number of Clicks on one House',fontsize=15)\n",
    "plt.ylabel('Probability Density',fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig('Results/HouseClickDistNoTitle.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means an average amount of 271/64 = 4.23 on each house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot((AllDf > 0).astype(int).sum(axis=0),norm_hist=False,kde=False,color='royalblue')\n",
    "plt.plot([np.mean((AllDf > 0).astype(int).sum(axis=0)), np.mean((AllDf > 0).astype(int).sum(axis=0))], [0, 17], linewidth=2)\n",
    "plt.yticks(np.arange(0, 21, step=5))\n",
    "plt.legend(['mean: '+str(np.mean((AllDf > 0).astype(int).sum(axis=0)))[:4],'distribution'],fontsize=15)\n",
    "plt.title(\"Distribution of Number of Houses That Were Looked at\",fontsize=20)\n",
    "plt.xlabel('Number of Houses That Were Looked at by a Subject',fontsize=15)\n",
    "plt.ylabel('Subject Count',fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig('Results/ClickedDistAbsCountNoTitle.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Whole Click Distribution -> Any (Ir)regularities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,35))\n",
    "sns.heatmap(AllDf)\n",
    "plt.title('Number of Clicks on Each House by Each Subject',fontsize=20)\n",
    "plt.ylabel('House Number',fontsize=15)\n",
    "plt.xlabel('Subject Number',fontsize=15)\n",
    "#plt.show()\n",
    "plt.savefig('Results/ClickHeatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Performance\n",
    "\n",
    "#### Load Data of Task Performance (.mat Files) into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_to_py(AlignmentPath,number):\n",
    "    '''\n",
    "    converts mat struct with task results into (numpy) array\n",
    "\n",
    "    also adds extra column with information whether trial was correct or wrong\n",
    "    \n",
    "    conditions = [\"Absolute - 3s \",\"Absolute - inf\",\"Relative - 3s \",\"Relative - inf\",\"Pointing 3s   \",\"Pointing - inf\"]\n",
    "    '''\n",
    "    path = AlignmentPath+\"/AlignmentVR_SubjNo_\"+number+\".mat\"\n",
    "    mat_contents = spio.loadmat(path)\n",
    "    type_array = []\n",
    "    for i,cond_1 in enumerate([\"Absolute\", \"Relative\",\"Pointing\"]):\n",
    "        for j,cond_2 in enumerate([\"Trial_3s\", \"Trial_Inf\"]):\n",
    "            trials_array = []\n",
    "            for line in range(len(mat_contents['Output'][0][0][cond_1][cond_2][0][0])):\n",
    "                value_array = []\n",
    "                for column in range(len(mat_contents['Output'][0][0][cond_1][cond_2][0][0][line][0])):\n",
    "                    value = mat_contents['Output'][0][0][cond_1][cond_2][0][0][line][0][column][0][0]\n",
    "                    value_array.append(value)\n",
    "                # check if trial is correct(true or false\n",
    "                value_array.append(value_array[-1] == value_array[-3])\n",
    "                trials_array.append(value_array)\n",
    "\n",
    "            type_array.append(trials_array)\n",
    "\n",
    "    return np.array(type_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"Absolute - 3s \",\"Absolute - inf\",\"Relative - 3s \",\"Relative - inf\",\"Pointing 3s   \",\"Pointing - inf\"]\n",
    "vp_nums = list(AllDf)\n",
    "AllResults = np.zeros((6,len(vp_nums),36))#AllResults[condition][subjectNum][Trial]\n",
    "AllHouses = np.zeros((6,len(vp_nums),36))\n",
    "LeastClickHouse = np.zeros((6,len(vp_nums),36))\n",
    "for i,e in enumerate(vp_nums):\n",
    "    try:\n",
    "        m = mat_to_py(taskPath,e)\n",
    "        for c in range(6):       \n",
    "            condperf = []\n",
    "            house = []\n",
    "            lchouse = []\n",
    "            for t in range(36):\n",
    "                condperf.append(int(m[c][t][-1]))\n",
    "                #print(m[c][t][0])\n",
    "                house.append(str(m[c][t][0]))\n",
    "                if c<2:#absolute condition -> only one house, take this one\n",
    "                    lchouse.append(str(m[c][t][0]))\n",
    "                else:#relative or pointing condition -> look if prime or target had more clicks, pick house with least clicks\n",
    "                    if AllDf.loc[int(m[c][t][0])][e]<AllDf.loc[int(m[c][t][1])][e]:\n",
    "                        lchouse.append(str(m[c][t][0]))\n",
    "                    else:\n",
    "                        lchouse.append(str(m[c][t][1]))\n",
    "                    \n",
    "            AllResults[c][i] = condperf\n",
    "            AllHouses[c][i] = house\n",
    "            LeastClickHouse[c][i] = lchouse      \n",
    "    except:\n",
    "        print(str(e)+\" Not in folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Performance Matrix and Save as .cvs File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = np.zeros((6,len(AllDf.columns)))#pd.DataFrame()\n",
    "vpN = pd.DataFrame(vp_nums,columns=['vp_number'])\n",
    "for cond in range(6):\n",
    "    performances[cond] = np.mean(AllResults[cond],axis=1)\n",
    "p = pd.DataFrame(np.transpose(performances)) \n",
    "p.columns = conditions\n",
    "p = vpN.join(p).set_index('vp_number')\n",
    "#p.to_csv('Results/MapPerformances.csv')#comment in to save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskList = ['Absolute','Absolute','Relative','Relative','Pointing','Pointing']\n",
    "CondList = ['3s','inf','3s','inf','3s','inf']\n",
    "AllPerformances = pd.DataFrame(columns=['Task','Condition','Performance','Subject'])\n",
    "for sj in list(p.index):\n",
    "    for i,c in enumerate(conditions):\n",
    "        AllPerformances = AllPerformances.append({'Task':TaskList[i],'Condition':CondList[i],'Performance':p.loc[sj][c],'Subject':sj}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Overall Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group tasks\n",
    "#color by time condition\n",
    "fig,ax = plt.subplots(figsize=(10,7))\n",
    "plt.plot([-5,10],[0.5,0.5],':',color='black', linewidth=5)\n",
    "sns.boxplot(data=AllPerformances,hue='Condition',x='Task',y='Performance', palette=[\"red\", \"royalblue\"],linewidth=2.5)\n",
    "ax.set_xticklabels(['Absolute','Relative','Pointing'],fontsize=15)\n",
    "ax.set_ylim((0,1))\n",
    "plt.legend(fontsize=20,loc=4)\n",
    "#plt.title('Performance of Subjects in the Tasks',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=20)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5,dtype=int),fontsize=15)\n",
    "plt.xlabel(\"Task\",fontsize=20)\n",
    "plt.show()\n",
    "#plt.savefig('Results/TaskPerformancesGrouped.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting adapted from https://peerj.com/preprints/27137v1/\n",
    "ax = pt.RainCloud(data=AllPerformances,hue='Condition',x='Task',y='Performance', palette=[\"red\", \"royalblue\"],bw = 0.2,\n",
    "                 width_viol = .5, figsize = (10,7),pointplot = False, alpha = .85, dodge = True, move = 0.2)\n",
    "\n",
    "ax.set_xticklabels(['Absolute','Relative','Pointing'],fontsize=15)\n",
    "#ax.legend(['3s','inf'],fontsize=20,loc=1)\n",
    "\n",
    "plt.title('Performance of Subjects in the Tasks',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=20)\n",
    "plt.xlabel(\"Task\",fontsize=20)\n",
    "plt.yticks(np.linspace(0.25,0.75,3),np.linspace(25,75,3),fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig('Results/TaskPerformancesRainCloud.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pt.RainCloud(data=AllPerformances[AllPerformances['Condition']=='inf'],x='Task',y='Performance', palette=[\"royalblue\"],bw = 0.2,\n",
    "                 width_viol = .5, figsize = (10,7),pointplot = False, alpha = .85, dodge = True, move = 0.2)\n",
    "plt.plot([-5,10],[0.5,0.5],':',color='black', linewidth=3)\n",
    "ax.set_xticklabels(['Absolute','Relative','Pointing'],fontsize=15)\n",
    "#ax.set_ylim((0,1))\n",
    "#ax.legend(['3s','inf'],fontsize=20)\n",
    "\n",
    "#plt.title('Performance of Subjects in the Tasks - Infinite',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=20)\n",
    "plt.yticks(np.linspace(0.25,0.75,3),np.linspace(25,75,3,dtype=int),fontsize=15)\n",
    "plt.xlabel(\"Task\",fontsize=20)\n",
    "plt.show()\n",
    "#plt.savefig('Results/TaskPerformancesRainCloud_Infinite_NoTitle.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Measure ANOVA for Tasks and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovarm = AnovaRM(AllPerformances,'Performance','Subject',within=['Task','Condition'])\n",
    "fit = anovarm.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorial ANOVA (One Way Repeated Measure) on Infinite Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infPerformances = AllPerformances[AllPerformances['Condition']=='inf']\n",
    "anovarm = AnovaRM(infPerformances,'Performance','Subject',within=['Task'])\n",
    "fit = anovarm.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Hoc Paired T-Test on Infinite Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Absolute - Relative: \"+str(stats.ttest_rel(infPerformances[infPerformances['Task']=='Absolute']['Performance'],infPerformances[infPerformances['Task']=='Relative']['Performance'])))\n",
    "print(\"Absolute - Pointing: \"+str(stats.ttest_rel(infPerformances[infPerformances['Task']=='Absolute']['Performance'],infPerformances[infPerformances['Task']=='Pointing']['Performance'])))\n",
    "print(\"Relative - Pointing: \"+str(stats.ttest_rel(infPerformances[infPerformances['Task']=='Relative']['Performance'],infPerformances[infPerformances['Task']=='Pointing']['Performance'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Different from chance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(newDF['Performance'], 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference in Performance Between Inf and 3 Sec Condition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(newDF['Performance'][newDF['Condition']=='inf'], newDF['Performance'][newDF['Condition']=='3s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_model = ols(\"Performance ~ Condition + Task\", data=newDF).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance in Relation to Clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllClickPerf2 = pd.DataFrame(columns = {'numClicks','Performance','Subject'})\n",
    "conds = [1,3,5]\n",
    "for c in conds:#range(6):\n",
    "    for i,s in enumerate(vp_nums):\n",
    "        for t in range(36):\n",
    "            house = LeastClickHouse[c][i][t]#AllHouses[c][i][t]\n",
    "            #print(int(house))\n",
    "            numviews = AllDf.loc[int(house)][s]\n",
    "            AllClickPerf2 = AllClickPerf2.append({'numClicks':numviews,'Performance':AllResults [c][i][t],'Subject':float(s)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Point for Each Subject-NumClick Combination Averaged Over Tasks and Trials\n",
    "Same procedure as explained in Lauras Bachelors Thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2 = AllClickPerf2.groupby(['Subject','numClicks'], as_index=False)['Performance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2.to_csv('Results/SubjectClickPerfSorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2 = pd.read_csv('Results/SubjectClickPerfSorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.lmplot(x='numClicks',y='Performance',data = grouped2,height=7,aspect=2,scatter_kws={\"s\": 30},x_jitter=.03,order=1,x_estimator=np.mean,fit_reg=True)\n",
    "plt.title('Performance in Relation to Number of Clicks - Infinite - Averaged over Tasks and Trials for Each Number of Clicks',fontsize=20)\n",
    "plt.xlabel('Number of Clicks',fontsize=15)\n",
    "plt.ylabel('Average Performance in %',fontsize=15)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "#plt.savefig('Results/ClickPerfInf_NumCAvg.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Using Log(Clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2['numClicks'] = np.log(grouped2['numClicks']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.lmplot(x='numClicks',y='Performance',data = grouped2[grouped2['numClicks']<100], height=7,aspect=2,palette=[\"royalblue\"],x_jitter=.09,lowess=False)\n",
    "#plt.title('Performance in Relation to Number of Clicks - Infinite - Averaged over Tasks and Trials for Each Number of Clicks',fontsize=20)\n",
    "plt.xlabel('Log(Number of Clicks)',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=25)\n",
    "#plt.xticks(np.linspace(0,60,7),fontsize=20)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5),fontsize=20)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "#plt.savefig('Results/ClickPerf_TTAvg_NoTitle_All.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model Based on Performance ~ Number of Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickperf_model = ols(\"Performance ~ numClicks\", data=grouped2).fit()\n",
    "print(clickperf_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Correlation:\n",
    "(correlation coefficient, p-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(grouped2['Performance'], grouped2['numClicks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Linear Regression\n",
    "Weighted by number of trials in one data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedWeighted = AllClickPerf2.groupby(['Subject','numClicks'], as_index=False).agg(['mean', 'count'])\n",
    "groupedWeighted.reset_index(inplace=True)\n",
    "weighted2 = pd.DataFrame(groupedWeighted.to_records())\n",
    "weighted2.columns = ['Ix','Subject','numClicks','Performance','Count']\n",
    "weighted2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import wls\n",
    "WLS = wls(\"Performance ~ numClicks\", data=weighted2,weights=np.array(1./weighted2['Count'])).fit()\n",
    "WLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2 = pd.read_csv('Results/SubjectClickPerfSorted.csv')\n",
    "grouped2['numClicks'] = np.log(grouped2['numClicks']+1)\n",
    "sns.lmplot(x='numClicks',y='Performance',data = grouped2[grouped2['numClicks']<100], height=7,aspect=1.4,palette=[\"royalblue\"],x_jitter=.03,lowess=False)\n",
    "#plt.title('Performance in Relation to Number of Clicks - Infinite - Averaged over Tasks and Trials for Each Number of Clicks',fontsize=20)\n",
    "plt.plot([0, 4], [0.4958, 0.4958+0.018], linewidth=3,color='orange',linestyle='-')\n",
    "plt.xlabel('Log(Number of Clicks)',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=25)\n",
    "plt.xticks(np.linspace(0,4,5),fontsize=20)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5),fontsize=20)\n",
    "plt.legend(['Linear Regression','Weighted Linear Regression'],fontsize=15)\n",
    "plt.xlim([0,4])\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "#plt.savefig('Results/ClickPerf_TTAvg_NoTitle_All.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Coverage of Seahaven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeahavenMap = Image.open('map5.png')\n",
    "coordinates = open(\"HouseList.txt\",\"r\")\n",
    "coords = pd.DataFrame(columns={'House','x','y'})\n",
    "for co in coordinates:\n",
    "    x = float(co.split(':',1)[1].split(';',1)[0])\n",
    "    y = float(co.split(';',1)[1])\n",
    "    house = str(co.split(':',1)[0])\n",
    "    coords = coords.append({'House':house,'x':x,'y':y},ignore_index=True)\n",
    "coords = coords.set_index('House').sort_index()\n",
    "overallClicks = np.sum(AllDf,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeahavenMap = Image.open('map5.png')\n",
    "coordinates = open(\"HouseList.txt\",\"r\")\n",
    "coords = pd.DataFrame(columns={'House','x','y'})\n",
    "for co in coordinates:\n",
    "    x = float(co.split(':',1)[1].split(';',1)[0])\n",
    "    y = float(co.split(';',1)[1])\n",
    "    house = str(co.split(':',1)[0])\n",
    "    coords = coords.append({'House':house,'x':x,'y':y},ignore_index=True)\n",
    "coords = coords.set_index('House').sort_index()\n",
    "SJNumClicks = np.sum(AllDf>0,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Houses by Amount of Clicks (Green-Few, Red-Many, Black-Not Included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "SeahavenMap = SeahavenMap.resize((450,500))\n",
    "ax = plt.subplot2grid((10, 10), (0, 0), colspan=9,rowspan=10)\n",
    "plt.imshow(SeahavenMap,aspect = 'equal')\n",
    "cmap = plt.cm.get_cmap('Greens')\n",
    "a=np.outer(np.arange(0,1,0.01),np.ones(3))\n",
    "for i in list(coords.index.values):\n",
    "    try:\n",
    "        clicks = overallClicks.loc[int(i)]\n",
    "        rgba = cmap((clicks-min(overallClicks))/(max(overallClicks)-min(overallClicks)))\n",
    "        ax.add_patch(Circle((coords['y'].loc[i]-535,coords['x'].loc[i]-180), radius=5, color=(rgba)))\n",
    "        #ax.add_patch(Circle((coords['y'].loc[i]-535,coords['x'].loc[i]-180), radius=5, color=((clicks-min(overallClicks))/(max(overallClicks)-min(overallClicks)),1-(clicks-min(overallClicks))/(max(overallClicks)-min(overallClicks)),0)))\n",
    "    except:\n",
    "        ax.add_patch(Circle((coords['y'].loc[i]-535,coords['x'].loc[i]-180), radius=5, color=(0,0,0)))\n",
    "    \n",
    "#plt.title('Overall Number of Clicks During Map Training',fontsize=20)\n",
    "ax2 = plt.subplot2grid((10, 10), (0, 9),rowspan=10)\n",
    "plt.imshow(a,aspect='auto',cmap='Greens',origin=\"lower\")\n",
    "ax2.get_xaxis().set_ticks([])\n",
    "ax2.get_yaxis().set_ticks(np.linspace(0,99,10))\n",
    "ax2.get_yaxis().set_ticklabels(np.around(np.linspace(min(overallClicks)/len(AllDf.columns),max(overallClicks)/len(AllDf.columns),10),2))\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_ylabel(\"Average Number of Clicks on House\",rotation=270, fontsize=15, labelpad=20)\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "plt.show()\n",
    "#plt.savefig('Results/MapClicks.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "SeahavenMap = SeahavenMap.resize((450,500))\n",
    "ax = plt.subplot2grid((10, 10), (0, 0), colspan=9,rowspan=10)\n",
    "plt.imshow(SeahavenMap,aspect = 'equal')\n",
    "cmap = plt.cm.get_cmap('Greens')\n",
    "a=np.outer(np.arange(0,1,0.01),np.ones(3))\n",
    "for i in list(coords.index.values):\n",
    "    try:\n",
    "        clicks = SJNumClicks.loc[int(i)]\n",
    "        rgba = cmap((clicks-min(SJNumClicks))/(max(SJNumClicks)-min(SJNumClicks)))\n",
    "        ax.add_patch(Circle((coords['y'].loc[i]-535,coords['x'].loc[i]-180), radius=5, color=(rgba)))\n",
    "        #ax.add_patch(Circle((coords['y'].loc[i]-535,coords['x'].loc[i]-180), radius=5, color=((clicks-min(overallClicks))/(max(overallClicks)-min(overallClicks)),1-(clicks-min(overallClicks))/(max(overallClicks)-min(overallClicks)),0)))\n",
    "    except:\n",
    "        continue\n",
    "        #ax.add_patch(Circle((coords['y'].loc[i]-535,coords['x'].loc[i]-180), radius=5, color=(0,0,0)))\n",
    "    \n",
    "#plt.title('Overall Number of Subjects Looking at Respective House During Map Training',fontsize=20)\n",
    "ax2 = plt.subplot2grid((10, 10), (0, 9),rowspan=10)\n",
    "plt.imshow(a,aspect='auto',cmap='Greens',origin=\"lower\")\n",
    "ax2.get_xaxis().set_ticks([])\n",
    "ax2.get_yaxis().set_ticks(np.linspace(0,99,10))\n",
    "ax2.get_yaxis().set_ticklabels(np.linspace((min(SJNumClicks)/len(AllDf.columns))*100,(max(SJNumClicks)/len(AllDf.columns))*100,10,dtype=int))\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_ylabel(\"Percentage of Subjects That Have Seen This House\",rotation=270, fontsize=15, labelpad=20)\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "plt.show()\n",
    "#plt.savefig('Results/MapSujClicks.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"complete_list_houses.txt\",\"r\")\n",
    "degreeDF = pd.DataFrame(columns={'Subject','Condition','AngularDiff','Performance'})\n",
    "angles = {}\n",
    "for line in f2:\n",
    "    house = int(line.split('_',1)[0].split('n',1)[0])\n",
    "    angle = int(line.split('_',1)[1].split('n',1)[0])\n",
    "    angles[house] = angle\n",
    "vp_nums = list(AllDf)\n",
    "degree_30 = np.zeros((6,2))\n",
    "degree_60 = np.zeros((6,2))\n",
    "degree_90 = np.zeros((6,2))\n",
    "degree_120 = np.zeros((6,2))\n",
    "degree_150 = np.zeros((6,2))\n",
    "degree_180 = np.zeros((6,2))\n",
    "degrees = []\n",
    "for i,e in enumerate(vp_nums):\n",
    "    m = mat_to_py(taskPath,e)\n",
    "    for cond in range(6):       \n",
    "        for trial in range(36):\n",
    "            degree = 0\n",
    "            if cond < 2 or cond >3: # abs und poi\n",
    "                degree = abs(int(m[cond][trial][-5])-int(m[cond][trial][-6])) # save angular diff in var\n",
    "            else: # rel\n",
    "                degree = abs(angles[m[cond][trial][-5]]-angles[m[cond][trial][-6]])\n",
    "            degrees.append(degree)\n",
    "            if degree <= 30 or degree >= 330:\n",
    "                degreeDF = degreeDF.append({'Subject':e,'Condition':cond,'AngularDiff':30,'Performance':float(m[cond][trial][-1])},ignore_index=True)\n",
    "                degree_30[cond][0] += 1 # increment counter for overall trial with 30 degree diff\n",
    "                if m[cond][trial][-1]:\n",
    "                    degree_30[cond][1] += 1 # increment counter for correct trial with 30 degree diff\n",
    "            elif degree <= 60 or degree >= 300:\n",
    "                degree_60[cond][0] += 1\n",
    "                degreeDF = degreeDF.append({'Subject':e,'Condition':cond,'AngularDiff':60,'Performance':float(m[cond][trial][-1])},ignore_index=True)\n",
    "                if m[cond][trial][-1]:\n",
    "                    degree_60[cond][1] += 1\n",
    "            elif degree <= 90 or degree >= 270:\n",
    "                degree_90[cond][0] += 1\n",
    "                degreeDF = degreeDF.append({'Subject':e,'Condition':cond,'AngularDiff':90,'Performance':float(m[cond][trial][-1])},ignore_index=True)\n",
    "                if m[cond][trial][-1]:\n",
    "                    degree_90[cond][1] += 1\n",
    "            elif degree <= 120 or degree >= 240:\n",
    "                degree_120[cond][0] += 1\n",
    "                degreeDF = degreeDF.append({'Subject':e,'Condition':cond,'AngularDiff':120,'Performance':float(m[cond][trial][-1])},ignore_index=True)\n",
    "                if m[cond][trial][-1]:\n",
    "                    degree_120[cond][1] += 1\n",
    "            elif degree <= 150 or degree >= 210:\n",
    "                degree_150[cond][0] += 1\n",
    "                degreeDF = degreeDF.append({'Subject':e,'Condition':cond,'AngularDiff':150,'Performance':float(m[cond][trial][-1])},ignore_index=True)\n",
    "                if m[cond][trial][-1]:\n",
    "                    degree_150[cond][1] += 1\n",
    "            else:\n",
    "                degree_180[cond][0] += 1\n",
    "                degreeDF = degreeDF.append({'Subject':e,'Condition':cond,'AngularDiff':180,'Performance':float(m[cond][trial][-1])},ignore_index=True)\n",
    "                if m[cond][trial][-1]:\n",
    "                    degree_180[cond][1] += 1\n",
    "allDegs = [degree_30,degree_60,degree_90,degree_120,degree_150,degree_180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot as Distribution:\n",
    "One dot = average performance of one participant over all trials with this orientation\n",
    "\n",
    "Plot like num click above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddegreeInf = groupeddegree[(groupeddegree['Condition']==1)|(groupeddegree['Condition']==3)|(groupeddegree['Condition']==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddegreeAllInf = groupeddegreeInf.groupby(['Subject','AngularDiff'], as_index=False)['Performance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddegreeAllInf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddegreeAllInf.to_csv('DegreePerformanceInf.csv')#Average performance for each subject - angular difference combination\n",
    "#over infinite task conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddegreeAllInf = pd.read_csv('Results/DegreePerformanceInf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "sns.lmplot(x='AngularDiff',y='Performance',data = groupeddegreeAllInf, height=7,aspect=1.4,palette=[\"royalblue\"],x_jitter=3,order=2)\n",
    "#plt.title('Performance in Relation to Angular Difference - Infinite \\n Averaged over Tasks and Trials with x Angular Difference for Each Subject',fontsize=20)\n",
    "plt.xlabel('Angular Difference',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=25)\n",
    "plt.xticks(np.linspace(0,180,7),fontsize=20)\n",
    "plt.xlim(20,190)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5,dtype=int),fontsize=20)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "#plt.savefig('Results/AngDiffPerfPoly.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot as Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pt.RainCloud(data=groupeddegreeAllInf,x='AngularDiff',y='Performance', palette=[\"royalblue\"],bw = 0.0,\n",
    "                 width_viol = .0, figsize = (10,7),pointplot=True,alpha = 1, dodge = True, move = 0.0)\n",
    "\n",
    "ax.set_xticklabels(np.linspace(30,180,6,dtype=int),fontsize=15)\n",
    "#plt.title('Average Performance of Subjects Dependent on Angular Difference of Houses',fontsize=25)\n",
    "plt.ylabel('Performance (%)',fontsize=20)\n",
    "plt.xlabel(\"Angular Difference\",fontsize=20)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5,dtype=int),fontsize=15)\n",
    "#plt.plot([-0.5, 9.5], [0.5291, 0.5291], linewidth=3,color='black',linestyle=':')\n",
    "plt.plot([-0.5, 9.5], [0.5, 0.5], linewidth=3,color='black',linestyle=':')\n",
    "plt.scatter(groupeddegreeAllInf['AngularDiff'],poly_2.predict(groupeddegreeAllInf['AngularDiff']), linewidth=3)\n",
    "plt.show()\n",
    "#plt.savefig('Results/AngDiffPerfRainCloud_NoTitle.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black line = median, Red line = Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovarm = AnovaRM(groupeddegreeAllInf,'Performance','Subject',within=['AngularDiff'])\n",
    "fit = anovarm.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_2 = smf.ols(formula='Performance ~ 1 + AngularDiff + I(AngularDiff  **2)', data=groupeddegreeAllInf).fit()\n",
    "poly_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(groupeddegreeAllInf['AngularDiff'],poly_2.predict(groupeddegreeAllInf['AngularDiff']), linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model for Angular Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angdiffperf_model = ols(\"Performance ~ AngularDiff\", data=groupeddegreeAllInf).fit()\n",
    "print(angdiffperf_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance in Relation to Distance Between Houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Binning, Average Over Subjects for Each House Combination\n",
    "Only run next 3 cells once, then just load the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = open(\"HouseList.txt\",\"r\")\n",
    "coords = pd.DataFrame(columns={'House','x','y'})\n",
    "for co in coordinates:\n",
    "    x = float(co.split(':',1)[1].split(';',1)[0])\n",
    "    y = float(co.split(';',1)[1])\n",
    "    house = str(int(co.split(':',1)[0]))\n",
    "    coords = coords.append({'House':house,'x':x,'y':y},ignore_index=True)\n",
    "coords = coords.set_index('House').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_nums = list(AllDf)\n",
    "m1 = mat_to_py(taskPath,vp_nums[0])\n",
    "houseOrder = []\n",
    "for c in range(6):\n",
    "    if c>1:\n",
    "        allHouseNum = [x[1] for x in np.array(m1[c])]\n",
    "        sort = np.sort(allHouseNum)\n",
    "    else:\n",
    "        allHouseNum = [x[0] for x in np.array(m1[c])]\n",
    "        sort = np.sort(allHouseNum)\n",
    "    houseOrder.append(list(sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"Absolute - 3s \",\"Absolute - inf\",\"Relative - 3s \",\"Relative - inf\",\"Pointing 3s   \",\"Pointing - inf\"]\n",
    "tasks = [\"Relative\",\"Relative\",\"Pointing\",\"Pointing\"]\n",
    "Conds = [\"3s\",\"inf\",\"3s\",\"inf\"]\n",
    "DistPerfDF = pd.DataFrame(columns={'Subject','Task','Condition','Distance','Performance','HouseCombination'})\n",
    "\n",
    "for i,e in enumerate(vp_nums):\n",
    "    try:\n",
    "        m = mat_to_py(taskPath,e)\n",
    "        for c in range(4):       \n",
    "            for t in range(36):\n",
    "                h1 = (coords['x'].loc[str(m[c+2][t][0])],coords['y'].loc[str(m[c+2][t][0])])\n",
    "                h2 = (coords['x'].loc[str(m[c+2][t][1])],coords['y'].loc[str(m[c+2][t][1])])\n",
    "                dist = distance.euclidean(h1, h2)\n",
    "                hC = houseOrder[c+2].index(m[c+2][t][1])\n",
    "                DistPerfDF = DistPerfDF.append({'Subject':e,'Task':tasks[c],'Condition':Conds[c],\n",
    "                                                'Distance':dist,'Performance':float(m[c+2][t][-1]),'HouseCombination':hC},ignore_index=True)     \n",
    "    except:\n",
    "        print(str(e)+\" Not in folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistPerfDF.to_csv(\"Results/DistancePerformanceAll.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistPerfDF = pd.read_csv(\"Results/DistancePerformanceAll.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = DistPerfDF.groupby(['HouseCombination','Task','Condition'], as_index=False)['Performance','Distance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.to_csv(\"Results/DistPerfGroupedMean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = pd.read_csv(\"Results/DistPerfGroupedMean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.regplot(x=\"Distance\", y=\"Performance\", data=group[group['Condition']==\"inf\"],color='royalblue',ci=95)\n",
    "#plt.title(\"Task Performance - Distance Between Houses in Seahaven \\n One Point = Task,Condition,House Combination Averaged Over Subjects\",fontsize=20)\n",
    "plt.xlabel(\"Distance (Unity Units)\",fontsize=20)\n",
    "plt.ylabel(\"Performance (%)\",fontsize=20)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5,dtype=int),fontsize=15)\n",
    "plt.xticks(np.linspace(0,400,9),fontsize=15)\n",
    "plt.ylim(0.2,0.8)\n",
    "plt.xlim(0,380)\n",
    "#plt.savefig('Results/DistPerfRegression_NoTitle.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distperf_model = ols(\"Performance ~ Distance\", data=group[group['Condition']==\"inf\"]).fit()\n",
    "print(distperf_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = os.listdir(mapPath)\n",
    "conditions = [\"Absolute - 3s \",\"Absolute - inf\",\"Relative - 3s \",\"Relative - inf\",\"Pointing 3s   \",\"Pointing - inf\"]\n",
    "g = open(\"./complete_list_houses.txt\",\"r\")\n",
    "allHouses = []\n",
    "for i in g:\n",
    "    allHouses.append(str(int(i.split('_',1)[0])))\n",
    "performances = pd.DataFrame(columns=['Subject','Measurement','Condition','Performance'])\n",
    "for e in allFiles:\n",
    "    if e.endswith(\".ods\"):\n",
    "        usable,code = checkUsability(int(e.split('.',1)[0]),Rep=True)    \n",
    "        if usable:\n",
    "            #print(ord(str(code)[1])-97)\n",
    "            m = mat_to_py(taskPath,(e.split('.',1)[0]))\n",
    "            for c in range(6):       \n",
    "                for t in range(36):\n",
    "                    performances = performances.append({'Subject': ord(str(code)[1])-97,'Measurement':int(str(code)[0])-1,\n",
    "                                                   'Condition':c,'Performance':int(m[c][t][-1])}, ignore_index=True)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(performances['Subject'])# List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances.to_csv(\"Results/RepeatedMPerformances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = pd.read_csv(\"Results/RepeatedMPerformances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Performances Averaged over 14 Repeated Measure Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances['Performance'] = performances['Performance'].astype(float)\n",
    "ax = sns.factorplot(x=\"Condition\", y=\"Performance\", hue=\"Measurement\",data=performances,\n",
    "                   size=5, kind=\"bar\", palette=\"Blues\",aspect=2, legend_out = False)\n",
    "ax.set_xticklabels(conditions,fontsize=12)\n",
    "ax.set_yticklabels(fontsize=12)\n",
    "ax.set_xlabels('Condition',fontsize=15)\n",
    "ax.set_ylabels('Performance',fontsize=15)\n",
    "l = plt.legend(title=\"Measurement\",fontsize=15)\n",
    "l.get_texts()[0].set_text('1')\n",
    "l.get_texts()[1].set_text('2')\n",
    "l.get_texts()[2].set_text('3')\n",
    "plt.setp(l.get_title(),fontsize=15)\n",
    "ax.fig.suptitle('Average Performance in Each Task for Three Measurements',fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig('Results/RepMeasPerf.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repgroup = performances.groupby(['Measurement','Subject','Condition'], as_index=False)['Performance'].mean()\n",
    "repgroup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repgroup.to_csv(\"Results/RepeatedMPerformanceGrouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repgroup = pd.read_csv(\"Results/RepeatedMPerformanceGrouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"Absolute \\n 3s \",\"Absolute \\n inf\",\"Relative \\n 3s \",\"Relative \\n inf\",\"Pointing \\n 3s   \",\"Pointing \\n inf\"]\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.boxplot(x=\"Condition\", y=\"Performance\", hue=\"Measurement\",data=repgroup,\n",
    "                   palette=sns.xkcd_palette(['lightblue','blue','denim blue']))\n",
    "ax.set_xticklabels(conditions,fontsize=15,rotation=0)\n",
    "l = plt.legend(title=\"Measurement\",fontsize=15,loc=4)\n",
    "l.get_texts()[0].set_text('1')\n",
    "l.get_texts()[1].set_text('2')\n",
    "l.get_texts()[2].set_text('3')\n",
    "plt.setp(l.get_title(),fontsize=15)\n",
    "plt.plot([-0.5, 9.5], [0.5, 0.5], linewidth=3,color='black',linestyle=':')\n",
    "plt.xlabel(\"Condition\",fontsize=20)\n",
    "plt.ylabel(\"Performance (%)\",fontsize=20)\n",
    "plt.yticks(np.linspace(0,1,5),np.linspace(0,100,5,dtype=int),fontsize=15)\n",
    "#plt.title('Average Performance in Each Task for Three Measurements',fontsize=25)\n",
    "#ax.fig.suptitle('Average Performance in Each Task for Three Measurements',fontsize=15)\n",
    "plt.show()\n",
    "#plt.savefig('Results/RepMeasPerfBox_NoTitle.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskTimeDF = pd.DataFrame(columns={'Subject','Measurement','Task','Time','Performance'})\n",
    "tasks = ['Absolute','Absolute','Relative','Relative','Pointing','Pointing']\n",
    "times = ['3s','inf','3s','inf','3s','inf']\n",
    "for i in range(252):\n",
    "    TaskTimeDF = TaskTimeDF.append({'Subject':repgroup['Subject'][i],'Measurement':repgroup['Measurement'][i],'Task':tasks[repgroup['Condition'][i]],'Time':times[repgroup['Condition'][i]],'Performance':repgroup['Performance'][i]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskTimeDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskTimeDF.to_csv(\"Results/RepeatedTaskTinePerformance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Measure ANOVA Within Task, Time and Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovarm = AnovaRM(TaskTimeDF,'Performance','Subject',within=['Task','Time','Measurement'])\n",
    "fit = anovarm.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRS Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frs = pd.read_excel('FRS_MAP_64_final_sk copy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frsDF = pd.DataFrame(columns={'Performance','Scale','Task'})\n",
    "for i in range(65):\n",
    "    frsDF = frsDF.append({'Performance':frs['AbsInf'][i],'Scale':frs['ScaleMean'][i],'Task':'Absolute Inf'},ignore_index=True)\n",
    "    frsDF = frsDF.append({'Performance':frs['RelInf'][i],'Scale':frs['ScaleMean'][i],'Task':'Relative Inf'},ignore_index=True)\n",
    "    frsDF = frsDF.append({'Performance':frs['PointInf'][i],'Scale':frs['ScaleMean'][i],'Task':'Pointing Inf'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "xlim = [1,7]\n",
    "ax.set_xlim(xlim)\n",
    "sns.regplot(x='ScaleMean', y='AbsInf', data=frs, ci=None, ax=ax,color='royalblue')\n",
    "sns.regplot(x='ScaleMean', y='RelInf', data=frs, ci=None, ax=ax,color='blue')\n",
    "sns.regplot(x='ScaleMean', y='PointInf', data=frs, ci=None, ax=ax,color='darkblue')\n",
    "plt.xlabel(\"Spatial Ability Score\",fontsize=20)\n",
    "plt.ylabel(\"Performance (%)\",fontsize=20)\n",
    "plt.yticks(np.linspace(20,80,4),np.linspace(20,80,4,dtype=int),fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.legend(['Absolute','Relative','Pointing'],fontsize=15,loc=4)\n",
    "ax.set_ylim([20,80])\n",
    "plt.show()\n",
    "#plt.savefig('Results/FRSPoiInfRegression_New.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Pointing Infinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frsPoiperf_model = ols(\"PointInf ~ ScaleMean\", data=frs).fit()\n",
    "print(frsPoiperf_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation:\n",
    "scipy.stats.pearsonr(frs['ScaleMean'][:64],frs['PointInf'][:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Absolute Infinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frsPoiperf_model = ols(\"AbsInf ~ ScaleMean\", data=frs).fit()\n",
    "print(frsPoiperf_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation:\n",
    "scipy.stats.pearsonr(frs['ScaleMean'][:64],frs['AbsInf'][:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Relative Infinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frsPoiperf_model = ols(\"RelInf ~ ScaleMean\", data=frs).fit()\n",
    "print(frsPoiperf_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation:\n",
    "scipy.stats.pearsonr(frs['ScaleMean'][:64],frs['RelInf'][:64])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
